{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " MIT 6.86x_HW1_charlotte.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sophia-JingMing/mit-6.86x/blob/feature/homeworks/homework%201.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6tGpYtc6asY"
      },
      "source": [
        "# Packages and libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAQaKOFS6pMs"
      },
      "source": [
        "import numpy as np\n",
        "from itertools import chain\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqivUh0CavL7"
      },
      "source": [
        "Assume:\n",
        "-There exits $\\theta^{*}$ such that $\\frac {y^{i}(\\theta^{*}x^{i})} {\\left\\|\\theta^{*}\\right\\|} \\geq \\gamma $ for all $i = 1, ...n $ and some $\\gamma > 0$\n",
        "- All the examples are bounded $\\left\\|x^{i}\\right\\| \\leq R, i = 1, ..., n$\n",
        "\n",
        "Then the number $k$ of updates mabe by the perceptron algorithm is bounded by $\\frac {R^{2}}{\\gamma^{2}}$.\n",
        "\n",
        "Note that the first condition implies that the data is linearly separable.\n",
        "\n",
        "Based on this theorem, what are the factors that constitute the bound on the number of mistakes made by the algorithm?\n",
        "\n",
        "\n",
        "A. Iteration order\n",
        "\n",
        "B. Maximum margin between positive and negative data points\n",
        "\n",
        "C. Maximum norm of data points\n",
        "\n",
        "D. Average norm of data points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8DoUAdW4prA"
      },
      "source": [
        "# 1. Perceptron Mistakes\n",
        "In this problem, we will investigate perceptron algorithm with different iteration ordering.\n",
        "\n",
        "Consider applying the perceptron algorithm through the origin based on a small training set containing three points:\n",
        "\n",
        "\n",
        "x|y\n",
        "---|---\n",
        "x(1)  =[-1,-1]|\t y(1) =1  \n",
        "x(2)  =[1,0]|\t y(2) =-1  \n",
        "x(3)  =[-1, 1.5]|\t y(3) =1\n",
        "\n",
        "Given that the algorithm starts with  $\\theta _{0}$=0 , the first point that the algorithm sees is always considered a mistake. The algorithm starts with some data point and then cycles through the data (in order) until it makes no further mistakes.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "028diqXjEIDH"
      },
      "source": [
        "(a)  \n",
        "4 points possible (graded)  \n",
        "How many mistakes does the algorithm make until convergence if the algorithm starts with data point $x_{1}$? How many mistakes does the algorithm make if it starts with data point $x_{2}$)?  \n",
        "\n",
        "Also provide the progression of the separating plane as the algorithm cycles in the following format: [[$\\theta_{1}1$, $\\theta_{1}2$],…,[$\\theta_{N}$)1, $\\theta_{N}$2]], where the superscript denotes different theta as the separating plane progresses. For example, if $\\theta$ progress from [0, 0] (initialization) to [1, 2] to [3, −2], you should enter [[1, 2],[3, −2]]  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6nVB_xYJNjQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f32c8a-8d86-4068-b31b-5b0fdbe99a08"
      },
      "source": [
        "def perceptron (x, y, theta = np.zeros(2),theta_0 = 0, start = 0) :\n",
        "    '''return the number of mistakes if start with x[start] until convergence'''\n",
        "    count = 0\n",
        "    theta_list = []\n",
        "    while True:\n",
        "        converged = True \n",
        "        for i in chain (range(start, x.shape[0]), range(start)): \n",
        "            if y[i] * (theta @ x[i]+ theta_0) <=0: \n",
        "                count +=1\n",
        "                theta += y[i] * x[i]\n",
        "                theta_0 += y[i]\n",
        "                theta_list.append(theta)\n",
        "                converged = False \n",
        "        if converged:\n",
        "            break\n",
        "    return theta_list,  count \n",
        "x = np.array([[-1, -1], [1, 0], [-1, 1.5]])\n",
        "y = np.array([1, -1, 1])\n",
        "print(perceptron(x, y, theta = np.zeros(2),theta_0 = 0, start = 0))\n",
        "perceptron(x, y, theta = np.zeros(2),theta_0 = 0, start = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "([array([-2., -1.]), array([-2., -1.])], 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([array([-2. ,  1.5]), array([-2. ,  1.5])], 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytbhOv5rLmZq"
      },
      "source": [
        "(c)  \n",
        "4 points possible (graded)  \n",
        "Now assume that x(3)=[−1,10]. How many mistakes does the algorithm make until convergence if cycling starts with data point x(1)?  \n",
        "\n",
        "Also provide the progression of the separating plane as the algorithm cycles in the following format: [[θ(1)1,θ(1)2],…,[θ(N)1,θ(N)2]], where the superscript denotes different theta as the separating plane progresses.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY7idBA4LrQb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1beaea5b-11dc-4cae-e99d-b6b24d16adee"
      },
      "source": [
        "x2 = np.array([[-1,-1], [1,0], [-1, 10]])\n",
        "y2 = np.array([1, -1, 1])\n",
        "print(perceptron(x2, y2))\n",
        "print(perceptron(x2, y2, start=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "([array([-5.,  7.]), array([-5.,  7.]), array([-5.,  7.]), array([-5.,  7.]), array([-5.,  7.])], 5)\n",
            "([array([-6.,  6.])], 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhOoT7qzM1Yk"
      },
      "source": [
        "(d)  \n",
        "1 point possible (graded)  \n",
        "For a fixed iteration order, what are the factors that affect the number of mistakes made by the algorithm between part (a) and part (c)?  \n",
        "\n",
        "Note: Only choose factors that were changed between part (a) and part (c), not all factors that can affect the number of mistakes  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIc2fvDfM54J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "10179e77-e5e4-45b5-f6dc-c240da598c69"
      },
      "source": [
        "plt.scatter(x[:, 0], x[:, 1], color = 'r', marker = '^')\n",
        "plt.scatter(x2[:, 0], x2[:, 1], color = 'b', alpha = .4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f665bfbf550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQyPJ3BDTSuM"
      },
      "source": [
        "# 2. Perceptron Performance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Oadzxk4TsqV"
      },
      "source": [
        "(a)  \n",
        "2 points possible (graded)  \n",
        "The following table shows a data set and the number of times each point is misclassified during a run of the perceptron algorithm (with offset θ0). θ and θ0 are initialized to zero.  \n",
        "\n",
        "i\tx(i)\ty(i)\ttimes misclassified  \n",
        "1\t[-4, 2]\t+1\t1  \n",
        "2\t[-2, 1]\t+1\t0  \n",
        "3\t[-1, -1]\t-1\t2  \n",
        "4\t[2, 2]\t-1\t1  \n",
        "5\t[1, -2]\t-1\t0  \n",
        "Write down the state of θ and θ0 after this run has completed (note, the algorithm may not yet have converged). Enter θ as a list [θ1,θ2] and θ0 as a single number in the following boxes.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxsUTvOxTzuf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f13c5c3d-5047-4ec8-de8a-55e7b7e62683"
      },
      "source": [
        "def misclassify(x, y, theta):\n",
        "    \"\"\"\n",
        "    Decision boundary: wx(i) = 0\n",
        "    w: if None, initialize to 0\n",
        "    \"\"\"\n",
        "    \n",
        "    theta_0 = 0\n",
        "    mistakes = []\n",
        "    while True:\n",
        "        converged = True\n",
        "        for i in range (x.shape[0]):\n",
        "            if y[i] * (theta @ x[i] + theta_0) <= 0:\n",
        "                theta += y[i] * x[i]\n",
        "                theta_0 += y[i]\n",
        "                mistakes.append(theta)\n",
        "                converged = False \n",
        "        if converged :\n",
        "            break \n",
        "    return mistakes, theta_0\n",
        "x3 = np.array([[-4, 2], [-2, 1], [-1, -1], [2, 2], [1, -2]])\n",
        "y3 = np.array([1, 1, -1, -1, -1])\n",
        "mistakes, weights = misclassify(x3, y3, theta = np.zeros (2))\n",
        "print(mistakes)\n",
        "print(weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([-3.,  3.]), array([-3.,  3.]), array([-3.,  3.]), array([-3.,  3.]), array([-3.,  3.])]\n",
            "-3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coRKqyWFob0S"
      },
      "source": [
        "(b)  \n",
        "2 points possible (graded)  \n",
        "Provide one example of a different initialization of θ such that the perceptron algorithm with this initialization would not produce any mistakes during a run through the data.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPdUx3eUoe6v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e13c8b2-ce3f-4e95-d45d-8f5445efa1ef"
      },
      "source": [
        "interval = range(-10, 11)\n",
        "theta_try\n",
        "for i in interval:\n",
        "    for j in range(len(interval)):\n",
        "        theta_try.append(np.array([i, interval[j]]))\n",
        "theta_try\n",
        "\n",
        "def idea_init(theta_list):\n",
        "    for i in range(len(theta_list)):\n",
        "        current_theta = theta_list[i]\n",
        "        if y[i] * (current_theta @ x[i]) <= 0:\n",
        "            continue\n",
        "        return current_theta\n",
        "idea_init(theta_try)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-10, -10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    }
  ]
}