{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPuY0y3yPSPF+YrhvVThWfI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sophia-JingMing/mit-6.86x/blob/feature/Homework_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoTa02MGPQ5M"
      },
      "source": [
        "#Packages and libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glikrqDbO_9-"
      },
      "source": [
        "import numpy as np\n",
        "from itertools import chain\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2D3WHXRTYMF"
      },
      "source": [
        "#1. Collaborative Filtering, Kernels, linear regression.\n",
        "In this question, we will use the alternating projections algorithm for low-rank matrix factorization, ehich aim to minimize:\n",
        "$\n",
        "J(U, V) = \\frac{1}{2}\\sum_{(a, i)\\in D}{}(Y_{ai} - [UV^{T}]_{ai})^{2} +\\frac{\\lambda}{2}\\sum_{a =1 }^{n}\\sum_{j = 1}^{k}U_{aj}^{2} + \\frac{\\lambda}{2}\\sum_{a =1 }^{m}\\sum_{j = 1}^{k}V_{ij}^{2}.\n",
        "$\n",
        "In the follwing, we will call the first tern the squared error term, and the two terms with $\\lambda$ the regularization terms.\n",
        "\n",
        "Let $Y$ be defined as:\n",
        "\n",
        "Y = \\begin{bmatrix}\n",
        " 5 & ? & 7\\\\ \n",
        " ? & 2 & ?\\\\ \n",
        " 4& ? & ?\\\\\n",
        " ? &3& 6\n",
        "\\end{bmatrix}\n",
        "$D$ is defined as the set of indices $(a, i)$, where $Y_{a, i}$ is not missing. In this problem, we let $k = \\lambda = 1$. Additionally, $U$ and $V$ are initialized as $U^{(0)} = [6, 0, 3, 6]^T $, and $v^{(0)} = [4, 2, 1]^T $\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOtkzVnQZxGW"
      },
      "source": [
        "##1a.\n",
        "Compute $X^{(0)}$, the matrix of predicted rankings $UV^T$ given the initial values for $U^{(0)}$ and $V^{(0)}$.\n",
        "\n",
        "(Matrix results, separated by the square brackets and commas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3G_g1jZaKel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a93f5ddd-2a2b-412e-967c-19acab24ff2b"
      },
      "source": [
        "u = np.array([6,0,3,6])\n",
        "v = np.array([4, 2, 1])\n",
        "x = np.zeros((u.shape[0], v.shape[0]))\n",
        "for i in range(u.shape[0]):\n",
        "    for j in range(v.shape[0]):\n",
        "        x[i][j] = u[i] *v [j]\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[24., 12.,  6.],\n",
              "       [ 0.,  0.,  0.],\n",
              "       [12.,  6.,  3.],\n",
              "       [24., 12.,  6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZlwWGNsv1DS"
      },
      "source": [
        "##1b\n",
        "Compute the squared error term, and the regularization terms in for the current estimate $X$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kireF9Tev0kz",
        "outputId": "89a6a0bd-5928-4b91-bb93-d7124be8a63b"
      },
      "source": [
        "y = np.array ([[5, 0, 7], [0, 2, 7], [4, 0, 0], [0, 3, 6]])\n",
        "sqrt = []\n",
        "for i in range (y.shape [0]):\n",
        "    for j in range (y.shape[1]):\n",
        "        if y[i][j] != 0:\n",
        "            sqrt.append(( y[i][j] - x[i][j])**2 / 2)\n",
        "        \n",
        "sqrt = sum(sqrt) # differ from staff ans (255.5)\n",
        "reg = 1/2 * ((np.linalg.norm(u))**2 + (np.linalg.norm(v))**2)\n",
        "print(sqrt)\n",
        "reg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "280.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51.0"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY_1BDdtdOUR"
      },
      "source": [
        "##1c.\n",
        "Suppose $V$ is kept fixed. Run one step of the algorithm to find the new estimate $U^{(1)}$.\n",
        "\n",
        "Enter the $U_{(1)}$ as list of numbers, $[ U_{1}^{(1)}, U_{2}^{(2)}, U_{3}^{(3)}, U_{4}^{(4)}] $:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QmQtWTqd3Pl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5fOpV2iPluj"
      },
      "source": [
        "#Perceptron updates#\n",
        "In this problem, we will try to undertand the convergence of perceptron algorithm and its relation to the ordering of the training samples for the following simple example.\n",
        "Consider a set of n=d labeled d-dimensional feature vectors, {x(t), y(t)), t=1, ...,d) defined as follows:\n",
        "x \n",
        "\n",
        "```\n",
        "x(t)i \t = \t cos(πt) if i=t \t \t(3.7)\n",
        "x(t)i \t = \t otherwise, \t \t(3.8)\n",
        "```\n",
        "Recall the no offset perceptron algorithm, and assume that θ⋅x=0 is treated as a mistake, regardless of label. assume that in all of the following problems, we initialize θ=0 and when we refer to the perceptron algorithm we only consider the no offset variant of it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_cX_OAjRjZZ"
      },
      "source": [
        "#Working out Perceptron algorithm\n",
        "3 points possible (graded)\n",
        "Consider the d=2 case. Let y(1) = 1, y(2) = 1. Assume that the feature vector x(1) is presented to the perceptron algorithm before x(2).\n",
        "For this particular assignment of labels, work out the perceptron algorithm until convergence.\n",
        "Let $\\hat{\\theta}$ be the resulting $\\theta$ value after convergece. Note that for d=2, $\\hat{\\theta} $ would be a 2 dimensional vector. Let's denote the first and second components of $\\hat{\\theta}$ by $\\hat{\\theta_{1}}$ and $\\hat{\\theta_{2}}$ respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59e-vvN3PjKZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc1ccdeb-ccbf-4682-faba-126973dce05b"
      },
      "source": [
        "def perceptron (x, y, theta,  fixed_offset = False, iters = 1000):\n",
        "    theta_list =[]\n",
        "    while True:\n",
        "        converged = True #cause we only excute when not converged\n",
        "        for i in range (x.shape[0]):\n",
        "            if y[i] * (theta @ x[i]) <= 0:\n",
        "                theta += y[i] *x[i]\n",
        "                theta_list.append(theta)\n",
        "        if converged:\n",
        "            break\n",
        "    return theta_list\n",
        "x = np.array([[np.cos(np.pi), 0],[1, np.cos(np.pi)]])\n",
        "y = np.array([1, 1])\n",
        "perceptron(x, y, theta = np.zeros((2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 0., -1.]), array([ 0., -1.])]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O9qdo82l2EX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}