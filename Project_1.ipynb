{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN9zksIg25OU6lThzhk1hdG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sophia-JingMing/mit-6.86x/blob/main/Project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DMSW-bBBmYo"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from string import punctuation, digits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr3_yRl0CihS"
      },
      "source": [
        "def get_order(n_samples):\n",
        "  try:\n",
        "    with open(str(n_samples) + '.txt') as fp:\n",
        "      line = fp.readline()\n",
        "      return list(map(int, line.split(',')))\n",
        "  except FileNotFoundError :\n",
        "    #random.seed(1)\n",
        "    indices = list(range(n_samples))\n",
        "    random.shuffle(indices)\n",
        "    return indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKCVwPdSMeSc"
      },
      "source": [
        "def extract_word(input_string):\n",
        "  \"\"\"helper function for bag_of_words()\n",
        "  input a text string\n",
        "  returns a list od lowercae word in the string\n",
        "  puctuation and digits are separated out into their own words\"\"\"\n",
        "  for c in punctuation +digits:\n",
        "    input_string = input_string.replace(c, ' ' + c +',')\n",
        "    return input_string.lower().split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCp0G6nqNfj7"
      },
      "source": [
        "def bag_of_words(texts):\n",
        "  \"\"\"input a list of string reviews\n",
        "  return a dictionary of unique unigrams occuring over the input \n",
        "  feel free to change this code as guided by problem 9\"\"\"\n",
        "  #read all stopwords.txt and save words from this file\n",
        "  with open(\"stopwords.txt\", 'r', encoding ='utf8') as stoptext:\n",
        "    stop_words= stoptext.read()\n",
        "    stop_words = stopwords.replace(\"\\n\", \" \").split()\n",
        "  dictionary ={}\n",
        "  for text in texts:\n",
        "    word_list = extract_words(text)\n",
        "    for word in word_list :\n",
        "      if word not in dictionary and word not in stop_words:\n",
        "        dictionary[word]= len(dictionary)\n",
        "  return dictionary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuTcE8tzPI_0"
      },
      "source": [
        "def extrac_bow_feature_vectors(reviews, dicttionary):\n",
        "  \"\"\"inputs a list of str reviews, the dictionary of words given by bag_of_words\n",
        "  return the bag_of_words feature matrix representation of the data\n",
        "  (shape (n, m)) : n : num of reviews, m: total nums of entries in the dictionary\n",
        "  feel free to edit \"\"\"\n",
        "  num_reviews = len(reviews)\n",
        "  feature_matrix = np.xeros([num_reviews, len(dictionary)])\n",
        "  for i, text in enumerate(reviews ):\n",
        "    word_list = extract_words(text)\n",
        "    for word in word_list:\n",
        "      if word in dictionary:\n",
        "        feature_matrix[i, dictionary[word]] += 1 \n",
        "  return feature_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx_1uw_CE5M-"
      },
      "source": [
        "#**HINGLE LOSS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2hby1VWE34j"
      },
      "source": [
        "def hingle_loss_single(feature_vector, label, theta, theta_0):\n",
        "  \"\"\"find the hingle loss on a single data point, given singke specific classification para.\n",
        "  return a real number representating the hingle loss associated with the given data point and paras\"\"\"\n",
        "  return np.max( 1- label * (theta@feature_vector + theta_0). np.zeros(2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a27HDKZpF2qc"
      },
      "source": [
        "def hingle_loss_full(feature_matrix, label, theta, theta_0):\n",
        "  \"\"\"find the total hingle loss on a set of data given specific classification paras\n",
        "  return a real number representating the hingle loss asscociated with the given dataset and paras.\n",
        "  this is the average hingle loss across all of the points in the feature matrix\"\"\"\n",
        "  return np.mean(1- labels[i]*(theta@feature_matrix[i] + theta_0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aFj-AbIGhv4"
      },
      "source": [
        "#**PERCEPTRON**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDO56cdjGnlQ"
      },
      "source": [
        "def perceptron_single_step_update( feature_vector, label, theta, theta_0):\n",
        "  \"\"\" update theta and theta_0 on a single step of PLA \n",
        "  return theta, theta_0 after current update has completed\"\"\"\n",
        "  if label *(theta @ feature_vector + theta_0 ) <= 0:\n",
        "    theta += label * feature_vector \n",
        "    theta_0 += label\n",
        "  return theta, theta_0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTm6_W1iHJK1"
      },
      "source": [
        "def perceptron (feature_matrix, labels, T):\n",
        "  \"\"\" run the T iterations PLA on a given set of data \n",
        "  return the final value of theta and theta_0\"\"\"\n",
        "  theta =np.zeros (2)\n",
        "  theta_0 = 0\n",
        "  for n in range (T) :\n",
        "    for i in get_order(feature_matrix.shape [0]):\n",
        "      theta, theta_0 = perceptron_single_step_update (feature_matrix [i], labels [i], theta, theta_0)\n",
        "    return theta,theta_0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ5sm3ygHwJc"
      },
      "source": [
        "def average_perceptron(feature_matrix, labels, T):\n",
        "  \"\"\"run T iterations through the data set, return average of theta and theta_0\n",
        "  NOTE: iterate the data matrix by the orders returned by get_order(feature_matrix.shape[0])\"\"\"\n",
        "  theta =np.zeros(2)\n",
        "  theta_0 = 0\n",
        "  theta_sum = np.zeros(2)      \n",
        "  theta_0_sum = 0      \n",
        "  n = feature_matrix.shape[0]\n",
        "  for t in range (T):\n",
        "    for i in get_order (n) :\n",
        "      theta, theta_0 = perceptron_single_step_update (feature_matrix[i], labels[i], current_theta, current_theta_0)\n",
        "      theta_sum += theta\n",
        "      theta_0_sum += theta_0 \n",
        "  return theta_sum/(n*T) , theta_0_sum/( n*T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "2kwJ9mvYVkde",
        "outputId": "bd6cfa7b-e403-45b8-eb05-81e93c6ecf04"
      },
      "source": [
        "feature_matrix = np.array([[1, 2]])    \n",
        "labels = np.array([1])    \n",
        "T = 2    \n",
        "exp_res = (np.array([1, 2]), 1)\n",
        "average_perceptron (feature_matrix, labels,2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-6d0bf43a2fe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mexp_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0maverage_perceptron\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-ed35fa7b1628>\u001b[0m in \u001b[0;36maverage_perceptron\u001b[0;34m(feature_matrix, labels, T)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_order\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperceptron_single_step_update\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mtheta_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mtheta_0_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtheta_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F54nOrcYVsAH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "1769d16b-ec54-493f-a985-8c75bbdea8ac"
      },
      "source": [
        "feature_matrix = np.array([[1, 2], [-1, 0]])    \n",
        "labels = np.array([1, 1])    \n",
        "T = 2    \n",
        "exp_res = (np.array([-0.25, 1.5]), 1.75)\n",
        "average_perceptron (feature_matrix, labels, 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-91e28304a795>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mexp_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0maverage_perceptron\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-ed35fa7b1628>\u001b[0m in \u001b[0;36maverage_perceptron\u001b[0;34m(feature_matrix, labels, T)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_order\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperceptron_single_step_update\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mtheta_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mtheta_0_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtheta_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2EpUaJK9kHe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg0ytCXfIea_"
      },
      "source": [
        "#**PEGASOS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKzmDVQ-IcBd"
      },
      "source": [
        "def pegasos_single_step_update(feature_vector, label, L, eta, current_theta, current_theta_0):\n",
        "  \"\"\" update theta and theta_0 after the current update is completed\"\"\"\n",
        "  if"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks82FZTRI9HC"
      },
      "source": [
        "def pegasos(feature_matrix, lables, T, L):\n",
        "  \"\"\" run T iterations PLA.\n",
        "  for each update, set learing rate = 1/ sqrt(t), where t is a counter for the num of performed so far( between 1 and nT)\n",
        "  return the last value of theta and theta_0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thTMoMA_JzeX"
      },
      "source": [
        "#**PART** **2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evbMMrJTKZ4N"
      },
      "source": [
        "#**CLASSIFIED**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVnR0Rd6JxZL"
      },
      "source": [
        "def classify(feature_matrix, theta, theta_0):\n",
        "  \"\"\" use theta and theta_0 to classify a set of data point \n",
        "  return a np array of 1s and -1s \n",
        "  where the k_th elms of the arr is the predicted classification of the k_th row of the feature matrix\n",
        "if a prediction is > 0, it should be considered a positive c;assification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgSNKVWqLdoF"
      },
      "source": [
        "def clasification_accuracy(classifer,\n",
        "                           train_feature_matrix,\n",
        "                           val_feature_matrix,\n",
        "                           train_labels,\n",
        "                           val_labels,\n",
        "                           **kwargs):\n",
        "  \"\"\" train a linear classifier using PLA with a given T value.\n",
        "  the classifier is trained on the train data\n",
        "  return a turple (scalar accuracy of the trained classifier on the training data set,\n",
        "                    accuracy of valid set )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWINmvE1Qljg"
      },
      "source": [
        "def accuracy(preds, targets):\n",
        "  \"\"\"given length-N vectors containing predicted and target lables\n",
        "  return the percentage and anumber of correct predictions\"\"\"\n",
        "  return (preds == targets).mean()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}